{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664\n",
      "690\n"
     ]
    }
   ],
   "source": [
    "# read Excel file\n",
    "df = pd.read_excel('stopwords.xlsx')\n",
    "\n",
    "# extract words from cells and convert to list\n",
    "words = df.values.flatten().tolist()\n",
    "\n",
    "words = [x for x in words if str(x) != 'nan']\n",
    "\n",
    "#print(words)\n",
    "\n",
    "new_words = []\n",
    "\n",
    "for word in words:\n",
    "    if \"'\" in word:\n",
    "        new_word = word.replace(\"'\", \"\")\n",
    "        new_words.append(new_word)\n",
    "    new_words.append(word)\n",
    "\n",
    "# print the list of words\n",
    "print(len(words))\n",
    "print(len(new_words))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "stopwords_df = pd.DataFrame({\"stopwords\":new_words})\n",
    "stopwords_df.to_csv('stopwords.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikol\\AppData\\Local\\Temp\\ipykernel_16032\\1098175798.py:2: DtypeWarning: Columns (4,5,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  script_df = pd.read_csv('Datasets/data-society-the-simpsons-by-the-data/simpsons_script_lines.csv')\n"
     ]
    }
   ],
   "source": [
    "stopwords_df = pd.read_csv('Datasets/scraped/stopwords.csv')\n",
    "script_df = pd.read_csv('Datasets/data-society-the-simpsons-by-the-data/simpsons_script_lines.csv')\n",
    "characters_df = pd.read_csv('Datasets/data-society-the-simpsons-by-the-data/simpsons_characters.csv')\n",
    "script_df['character_id'] = script_df['character_id'].fillna(0).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "id                                                                 4263\nepisode_id                                                           14\nnumber                                                              255\nraw_text              Entire Town: \"GONE AWAY IS THE BLUEBIRD / HERE...\ntimestamp_in_ms                                                 1141000\nspeaking_line                                                      TRUE\ncharacter_id                                                        241\nlocation_id                                                       211.0\nraw_character_text                                          Entire Town\nraw_location_text                                          NEIGHBORHOOD\nspoken_words          GONE AWAY IS THE BLUEBIRD / HERE TO STAY...,go...\nnormalized_text        WITH HEART) \"\"Chapter Six: Four Days in Phila...\nword_count                                                    1154000.0\nUnnamed: 13                                                         NaN\nUnnamed: 14                                                         NaN\nUnnamed: 15                                                         NaN\nUnnamed: 16                                                         NaN\nUnnamed: 17                                                         NaN\nUnnamed: 18                                                         NaN\nUnnamed: 19                                                         NaN\nUnnamed: 20                                                         NaN\nUnnamed: 21                                                         NaN\nUnnamed: 22                                                         NaN\nUnnamed: 23                                                         NaN\nUnnamed: 24                                                       212.0\nUnnamed: 25                                                         NaN\nUnnamed: 26                          CONTINENTAL CONGRESS, PHILADELPHIA\nName: 153016, dtype: object"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_df.iloc[153016]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "     id  episode_id  number  \\\n0  9549          32     209   \n1  9550          32     210   \n2  9551          32     211   \n3  9552          32     212   \n4  9553          32     213   \n\n                                            raw_text timestamp_in_ms  \\\n0  Miss Hoover: No, actually, it was a little of ...          848000   \n1  Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?          856000   \n2  Miss Hoover: I don't know. Although I'd sure l...          856000   \n3           Lisa Simpson: That life is worth living.          864000   \n4  Edna Krabappel-Flanders: The polls will be ope...          864000   \n\n  speaking_line  character_id  location_id       raw_character_text  \\\n0          True           464          3.0              Miss Hoover   \n1          True             9          3.0             Lisa Simpson   \n2          True           464          3.0              Miss Hoover   \n3          True             9          3.0             Lisa Simpson   \n4          True            40          3.0  Edna Krabappel-Flanders   \n\n               raw_location_text  ... Unnamed: 17 Unnamed: 18  Unnamed: 19  \\\n0  Springfield Elementary School  ...         NaN         NaN          NaN   \n1  Springfield Elementary School  ...         NaN         NaN          NaN   \n2  Springfield Elementary School  ...         NaN         NaN          NaN   \n3  Springfield Elementary School  ...         NaN         NaN          NaN   \n4  Springfield Elementary School  ...         NaN         NaN          NaN   \n\n   Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  Unnamed: 24  \\\n0          NaN          NaN          NaN          NaN          NaN   \n1          NaN          NaN          NaN          NaN          NaN   \n2          NaN          NaN          NaN          NaN          NaN   \n3          NaN          NaN          NaN          NaN          NaN   \n4          NaN          NaN          NaN          NaN          NaN   \n\n   Unnamed: 25  Unnamed: 26  \n0          NaN          NaN  \n1          NaN          NaN  \n2          NaN          NaN  \n3          NaN          NaN  \n4          NaN          NaN  \n\n[5 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>episode_id</th>\n      <th>number</th>\n      <th>raw_text</th>\n      <th>timestamp_in_ms</th>\n      <th>speaking_line</th>\n      <th>character_id</th>\n      <th>location_id</th>\n      <th>raw_character_text</th>\n      <th>raw_location_text</th>\n      <th>...</th>\n      <th>Unnamed: 17</th>\n      <th>Unnamed: 18</th>\n      <th>Unnamed: 19</th>\n      <th>Unnamed: 20</th>\n      <th>Unnamed: 21</th>\n      <th>Unnamed: 22</th>\n      <th>Unnamed: 23</th>\n      <th>Unnamed: 24</th>\n      <th>Unnamed: 25</th>\n      <th>Unnamed: 26</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9549</td>\n      <td>32</td>\n      <td>209</td>\n      <td>Miss Hoover: No, actually, it was a little of ...</td>\n      <td>848000</td>\n      <td>True</td>\n      <td>464</td>\n      <td>3.0</td>\n      <td>Miss Hoover</td>\n      <td>Springfield Elementary School</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9550</td>\n      <td>32</td>\n      <td>210</td>\n      <td>Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?</td>\n      <td>856000</td>\n      <td>True</td>\n      <td>9</td>\n      <td>3.0</td>\n      <td>Lisa Simpson</td>\n      <td>Springfield Elementary School</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9551</td>\n      <td>32</td>\n      <td>211</td>\n      <td>Miss Hoover: I don't know. Although I'd sure l...</td>\n      <td>856000</td>\n      <td>True</td>\n      <td>464</td>\n      <td>3.0</td>\n      <td>Miss Hoover</td>\n      <td>Springfield Elementary School</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9552</td>\n      <td>32</td>\n      <td>212</td>\n      <td>Lisa Simpson: That life is worth living.</td>\n      <td>864000</td>\n      <td>True</td>\n      <td>9</td>\n      <td>3.0</td>\n      <td>Lisa Simpson</td>\n      <td>Springfield Elementary School</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9553</td>\n      <td>32</td>\n      <td>213</td>\n      <td>Edna Krabappel-Flanders: The polls will be ope...</td>\n      <td>864000</td>\n      <td>True</td>\n      <td>40</td>\n      <td>3.0</td>\n      <td>Edna Krabappel-Flanders</td>\n      <td>Springfield Elementary School</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def extract_top_k_keywords(character_id, k):\n",
    "    print(characters_df.loc[characters_df['id']==character_id]['name'])\n",
    "    text_list = script_df.loc[script_df['character_id']==character_id]['raw_text'].tolist()\n",
    "    text_list = [x for x in text_list if str(x) != 'nan']\n",
    "    vectorizer = TfidfVectorizer(stop_words=stopwords_df['stopwords'].tolist(), lowercase=True, min_df=0.05, max_df=0.95)\n",
    "    tf_idf_matrix = vectorizer.fit_transform(text_list)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Get the average tf-idf score for each feature across all documents\n",
    "    feature_scores = tf_idf_matrix.mean(axis=0).tolist()[0]\n",
    "\n",
    "    # Create a dictionary mapping feature names to their tf-idf scores\n",
    "    feature_dict = dict(zip(feature_names, feature_scores))\n",
    "\n",
    "    # Sort the features by tf-idf score and return the top k features\n",
    "    top_k_features = sorted(feature_dict.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "    # Extract the feature names from the top k features and return them as a list\n",
    "    top_k_keywords = [feature[0] for feature in top_k_features]\n",
    "\n",
    "    return top_k_keywords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6659    Homer Simpson\n",
      "Name: name, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\Programming\\datamadness\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['al', 'didn', 'doesn', 'don', 'hasn', 'haven', 'isn', 'shouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "['marge', 'don']"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_top_k_keywords(2, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}